<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Alex â€” Modular Metacognitive Chatbot</title>

  <!-- Natural.js: NLP / sentiment â€” pinned to 6.12.0 to avoid @latest drift -->
  <script src="https://unpkg.com/natural@6.12.0/lib/natural.js"></script>
  <!-- TensorFlow.js: neural intent classifier (Phase 2 NLU) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.18.0/dist/tf.min.js"></script>

  <style>
    /* â”€â”€ CSS Variables & Reset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    :root {
      --font-size-base: 16px;
      --line-height-base: 1.6;
      --sp: 8px;
      --radius: 8px;
      --c-text: #333;
      --c-text-sub: #666;
      --c-bg: #f5f5f5;
      --c-bg-dark: #eee;
      --c-border: #ccc;
      --c-btn: #007bff;
      --c-btn-text: #fff;
      --c-btn-hover: #0056b3;
      --mood-happy: #4CAF50;
      --mood-neutral: #FFC107;
      --mood-frustrated: #F44336;
    }

    *, *::before, *::after { box-sizing: border-box; }

    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen,
                   Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif;
      font-size: var(--font-size-base);
      line-height: var(--line-height-base);
      color: var(--c-text);
      margin: 0;
      background: var(--c-bg);
      display: flex;
      flex-direction: column;
      min-height: 100vh;
    }

    /* â”€â”€ Status Bar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    #status-bar {
      width: 100%;
      background: #333;
      color: #fff;
      padding: var(--sp) calc(2 * var(--sp));
      display: flex;
      align-items: center;
      justify-content: space-between;
      font-size: 0.9em;
      box-shadow: 0 2px 4px rgba(0,0,0,.15);
      position: sticky;
      top: 0;
      z-index: 1000;
    }

    #status-bar .mood-pill {
      height: 12px;
      width: 56px;
      border-radius: var(--radius);
      background: var(--mood-neutral);
      transition: background .4s ease;
      margin-left: var(--sp);
      display: inline-block;
      vertical-align: middle;
    }

    #status-mood-label { margin-left: 6px; }

    #status-votes { font-size: 0.85em; opacity: .8; }

    /* â”€â”€ Chat Container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    #chat-container {
      flex-grow: 1;
      display: flex;
      flex-direction: column;
      max-width: 800px;
      width: 100%;
      margin: calc(2 * var(--sp)) auto;
      background: #fff;
      border-radius: var(--radius);
      box-shadow: 0 0 15px rgba(0,0,0,.07);
      overflow: hidden;
    }

    /* â”€â”€ Chat Window â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    #chat-window {
      flex-grow: 1;
      min-height: 420px;
      max-height: 60vh;
      padding: calc(2 * var(--sp));
      overflow-y: auto;
      border-bottom: 1px solid var(--c-bg-dark);
      scroll-behavior: smooth;
      -webkit-overflow-scrolling: touch;
    }

    /* â”€â”€ Messages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    .message {
      padding: var(--sp) calc(1.5 * var(--sp));
      margin-bottom: var(--sp);
      border-radius: var(--radius);
      max-width: 75%;
      line-height: 1.5;
      word-wrap: break-word;
      position: relative;
      transition: background-color .4s ease;
    }

    .user-message {
      background: var(--c-btn);
      color: var(--c-btn-text);
      margin-left: auto;
    }

    .bot-message {
      background: var(--c-bg-dark);
      color: var(--c-text);
      margin-right: auto;
      padding-bottom: calc(2.2 * var(--sp)); /* room for feedback row */
    }

    /* bot message text node wrapper */
    .bot-message .msg-text {
      white-space: pre-wrap;
    }

    /* â”€â”€ Feedback Buttons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    .feedback-row {
      position: absolute;
      bottom: 4px;
      right: 8px;
      display: flex;
      gap: 4px;
    }

    .feedback-row button {
      font-size: 0.78em;
      padding: 2px 6px;
      border: 1px solid var(--c-border);
      border-radius: 4px;
      cursor: pointer;
      background: #fff;
      line-height: 1.4;
      transition: background .2s;
    }

    .feedback-row button:hover { background: #e0e0e0; }
    .feedback-row button:focus {
      outline: none;
      box-shadow: 0 0 0 2px rgba(0,123,255,.4);
    }

    /* Module tag (small annotation) */
    .module-tag {
      font-size: 0.76em;
      color: var(--c-text-sub);
      display: block;
      margin-top: 4px;
    }

    /* â”€â”€ Input Area â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    #input-area {
      display: flex;
      padding: calc(1.5 * var(--sp));
      gap: var(--sp);
      background: #fff;
    }

    /* Visually-hidden label for accessibility */
    .sr-only {
      position: absolute;
      width: 1px; height: 1px;
      padding: 0; margin: -1px;
      overflow: hidden;
      clip: rect(0,0,0,0);
      white-space: nowrap;
      border: 0;
    }

    #chat-input {
      flex-grow: 1;
      padding: var(--sp);
      border: 1px solid var(--c-border);
      border-radius: var(--radius);
      font-size: var(--font-size-base);
      line-height: var(--line-height-base);
      resize: vertical;
      min-height: 40px;
      max-height: 150px;
      font-family: inherit;
    }

    #chat-input:focus {
      outline: none;
      border-color: var(--c-btn);
      box-shadow: 0 0 0 3px rgba(0,123,255,.25);
    }

    #send-button {
      padding: var(--sp) calc(2 * var(--sp));
      background: var(--c-btn);
      color: var(--c-btn-text);
      border: none;
      border-radius: var(--radius);
      font-size: var(--font-size-base);
      font-family: inherit;
      cursor: pointer;
      transition: background .2s;
      min-width: 80px;
    }

    #send-button:hover { background: var(--c-btn-hover); }
    #send-button:focus {
      outline: none;
      box-shadow: 0 0 0 3px rgba(0,123,255,.5);
    }

    /* â”€â”€ Meta / Thought Panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    #meta-panel-container {
      position: fixed;
      bottom: 0;
      right: 0;
      width: 320px;
      background: #f0f0f0;
      border: 1px solid #ccc;
      border-radius: var(--radius) 0 0 0;
      font-family: monospace;
      z-index: 999;
      box-shadow: -2px -2px 8px rgba(0,0,0,.1);
    }

    #meta-panel-header {
      padding: 6px 8px;
      background: #ddd;
      cursor: pointer;
      user-select: none;
      display: flex;
      justify-content: space-between;
      align-items: center;
      border-radius: var(--radius) 0 0 0;
    }

    #meta-panel-header span { font-size: 0.9em; }

    #meta-toggle-btn {
      border: none;
      background: #555;
      color: #fff;
      cursor: pointer;
      border-radius: 3px;
      font-size: 0.8em;
      padding: 2px 8px;
    }

    #meta-panel-content {
      margin: 0;
      padding: 6px;
      max-height: 200px;
      overflow-y: auto;
      background: #fff;
      border-top: 1px solid #ccc;
      font-size: 11px;
      white-space: pre-wrap;
      word-wrap: break-word;
      display: block; /* toggled via JS */
    }

    /* â”€â”€ Responsive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    @media (max-width: 600px) {
      :root { --font-size-base: 15px; }

      #chat-container {
        margin: 0;
        border-radius: 0;
        box-shadow: none;
      }

      #chat-window { padding: var(--sp); }

      .message { max-width: 90%; }

      #input-area { padding: var(--sp); }

      #send-button { min-width: 70px; padding: var(--sp) calc(1.5 * var(--sp)); }

      #meta-panel-container { width: 90%; right: 5%; }
    }
  </style>
</head>
<body>

  <!-- â”€â”€ Status Bar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
  <div id="status-bar" role="status" aria-live="polite">
    <div>
      <strong>Alex</strong> Â· Metacognitive Chatbot
      <span class="mood-pill" id="status-mood-pill" title="Current mood"></span>
      <span id="status-mood-label">Mood: neutral</span>
    </div>
    <div id="status-votes">ğŸ‘ 0 &nbsp; ğŸ‘ 0</div>
  </div>

  <!-- â”€â”€ Chat Container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
  <main id="chat-container">
    <div
      id="chat-window"
      role="log"
      aria-live="polite"
      aria-label="Chat messages"
    ></div>

    <div id="input-area">
      <label for="chat-input" class="sr-only">Your message</label>
      <textarea
        id="chat-input"
        rows="1"
        placeholder="Type your message and press Enterâ€¦"
        aria-label="Type your message"
      ></textarea>
      <button id="send-button" aria-label="Send message">Send</button>
    </div>
  </main>

  <!-- â”€â”€ Meta Panel (Internal Thoughts) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
  <div id="meta-panel-container" role="complementary" aria-label="Internal thought trace">
    <div id="meta-panel-header" role="button" tabindex="0" aria-expanded="true">
      <span>ğŸ§  Internal Thoughts</span>
      <button id="meta-toggle-btn" aria-label="Toggle thought panel">Hide</button>
    </div>
    <pre id="meta-panel-content">No thoughts recorded yet.</pre>
  </div>

  <!-- â”€â”€ Dev Neural Training Panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ -->
  <div id="dev-panel" style="
    position:fixed; bottom:0; left:0; width:260px;
    background:#1e1e2e; color:#cdd6f4; font-family:monospace;
    font-size:11px; border-radius:0 8px 0 0; border:1px solid #45475a;
    z-index:998; box-shadow:2px -2px 8px rgba(0,0,0,.3);">
    <div id="dev-panel-header" style="
      padding:5px 8px; background:#313244; cursor:pointer;
      display:flex; justify-content:space-between; align-items:center;
      border-radius:0 8px 0 0;" role="button" tabindex="0">
      <span>âš—ï¸ Neural NLU Dev</span>
      <button id="dev-toggle-btn" style="
        border:none; background:#45475a; color:#cdd6f4;
        cursor:pointer; border-radius:3px; font-size:10px; padding:2px 6px;"
        aria-label="Toggle dev panel">Hide</button>
    </div>
    <div id="dev-panel-body" style="padding:8px;">
      <div id="neural-status" style="margin-bottom:6px; color:#a6e3a1;">
        â³ Checking for saved modelâ€¦
      </div>
      <button id="btn-train-neural" style="
        width:100%; padding:5px; background:#89b4fa; color:#1e1e2e;
        border:none; border-radius:4px; cursor:pointer; font-size:11px;
        font-family:monospace; margin-bottom:4px;">
        ğŸš€ Train Neural NLU (seed data)
      </button>
      <button id="btn-train-with-feedback" style="
        width:100%; padding:5px; background:#a6e3a1; color:#1e1e2e;
        border:none; border-radius:4px; cursor:pointer; font-size:11px;
        font-family:monospace;">
        â• Train with ğŸ‘ conversation data
      </button>
      <div id="train-progress" style="margin-top:6px; color:#f9e2af; min-height:16px;"></div>
    </div>
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
       SINGLE SCRIPT BLOCK â€” all modules + coordinator + UI
       â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <script>
  /* ================================================================
     SECTION 1 â€” selfModel  (global singleton, spec Â§Core data)
     ================================================================ */
  const selfModel = {
    identity: {
      name: 'Alex-Web-Agent',
      version: '0.1',
      description: 'Browser-only modular chatbot with simulated metacognition'
    },
    capabilities: [
      'Basic NLU (rule-based intents)',
      'Sentiment-based emotion simulation',
      'Short/long-term memory via Web Storage',
      'Self-reflection text',
      'Simple policy adaptation from feedback'
    ],
    limitations: [
      'No real backend or LLM',
      'Runs only in browser',
      'Heuristic reasoning, no deep understanding',
      'Non-persistent learning beyond localStorage heuristics'
    ],
    state: {
      energy: 100,
      confidence: 80,
      lastFeedback: null,
      totalUpVotes: 0,
      totalDownVotes: 0,
      policy: {
        verbosityLevel: 0.5,   // 0â€“1
        humorLevel: 0.3,       // 0â€“1
        cautionLevel: 0.4      // 0â€“1
      }
    },
    emotionalVector: {
      happiness: 0.5,
      curiosity: 0.7,
      frustration: 0.0
    },
    updateState(update) { Object.assign(this.state, update); },
    updateEmotions(update) {
      // Clamp every incoming emotion value to [0, 1] to prevent drift
      const clamped = {};
      for (const [k, v] of Object.entries(update)) {
        clamped[k] = Math.max(0, Math.min(1, v));
      }
      Object.assign(this.emotionalVector, clamped);
    }
  };

  /* ================================================================
     SECTION 2 â€” MetaLog  (metacognitive trace)
     ================================================================ */
  const MetaLog = {
    _steps: [],
    maxSteps: 200,
    // Owned here so early log() calls during module construction
    // can safely check visibility before the panel IIFE in Section 13 runs.
    _panelVisible: true,

    log(stage, detail) {
      this._steps.push({ timestamp: new Date().toISOString(), stage, detail });
      if (this._steps.length > this.maxSteps) this._steps.shift();
      // Refresh panel only if visible and DOM is available
      if (this._panelVisible && typeof document !== 'undefined') {
        this._refreshPanel();
      }
    },

    recent(n = 10) {
      return this._steps.slice(-n)
        .map(e => `[${new Date(e.timestamp).toLocaleTimeString()}] [${e.stage}] ${e.detail}`)
        .join('\n');
    },

    _refreshPanel() {
      // Guard: panel element may not exist if logs fire before DOM is ready
      if (typeof document === 'undefined') return;
      const el = document.getElementById('meta-panel-content');
      if (el) el.textContent = this.recent(10) || 'No thoughts yet.';
    }
  };

  // Expose for any legacy references
  window.MetaLog = MetaLog;

  /* ================================================================
     SECTION 3 â€” MemoryModule
     ================================================================ */
  class MemoryModule {
    constructor() {
      try {
        this.shortTerm = JSON.parse(sessionStorage.getItem('shortTermMemory') || '[]');
        this.longTerm  = JSON.parse(localStorage.getItem('longTermMemory')   || '[]');
      } catch (e) {
        this.shortTerm = [];
        this.longTerm  = [];
      }
    }

    recall(type, key) {
      const mem = type === 'short' ? this.shortTerm : this.longTerm;
      const hit = mem.slice().reverse().find(e => e.key === key);
      return hit ? hit.value : null;
    }

    store(type, key, value) {
      const mem = type === 'short' ? this.shortTerm : this.longTerm;
      const storageKey = type === 'short' ? 'shortTermMemory' : 'longTermMemory';
      const store = type === 'short' ? sessionStorage : localStorage;

      // Build candidate array first; only mutate in-memory state if
      // storage write succeeds (or storage is unavailable but we accept it).
      const candidate = [...mem, { key, value }];
      try {
        store.setItem(storageKey, JSON.stringify(candidate));
        // Storage succeeded â€” commit to in-memory array
        mem.push({ key, value });
      } catch (e) {
        // Storage is full or blocked â€” still push to in-memory so the session
        // continues to work, but log the failure so it's not silently invisible.
        console.warn(`MemoryModule: ${type} storage write failed (quota/blocked). In-memory only.`, e);
        mem.push({ key, value });
      }
      MetaLog.log('memory', `store(${type}, ${key})`);
    }
  }

  /* ================================================================
     SECTION 4 â€” PerceptionModule
     ================================================================ */
  class PerceptionModule {
    perceive(input) {
      const time = new Date().toLocaleTimeString();
      MetaLog.log('perception', `Input received at ${time}: "${input.slice(0, 60)}${input.length > 60 ? 'â€¦' : ''}"`);
      return `Perceiving: "${input}" at ${time}.`;
    }
  }

  /* ================================================================
     SECTION 5 â€” EmotionModule
     (Natural.js SentimentAnalyzer â€” AFINN, lazy-initialized)
     Falls back to a minimal keyword scorer if CDN is unavailable.
     Custom domain lexicon is checked first for any token match,
     then AFINN/fallback handles the remainder.
     ================================================================ */
  class EmotionModule {
    constructor() {
      this._analyzer = null;

      // Domain-specific sentiment overrides â€” add/tune to your use case.
      // Values are in the same scale as AFINN: roughly -1.0 to +1.0.
      this._customLexicon = {
        // Positive domain terms
        'feature':     0.3,
        'performance': 0.4,
        'fast':        0.4,
        'smooth':      0.3,
        'clever':      0.5,
        'helpful':     0.6,
        // Negative domain terms
        'bug':        -0.8,
        'crash':      -0.9,
        'broken':     -0.8,
        'latency':    -0.6,
        'lag':        -0.5,
        'error':      -0.7,
        'fail':       -0.7
      };
    }

    /** Lazy getter â€” tries once per call until Natural.js is ready.
     *  If Natural.js never loads, installs a lightweight keyword fallback
     *  so sentiment analysis still produces meaningful signals offline. */
    _getAnalyzer() {
      if (this._analyzer) return this._analyzer;

      if (typeof natural !== 'undefined') {
        try {
          this._analyzer = new natural.SentimentAnalyzer(
            'English', natural.PorterStemmer, 'afinn'
          );
          return this._analyzer;
        } catch (e) {
          console.warn('EmotionModule: SentimentAnalyzer init failed.', e);
        }
      }

      // Offline / CDN-blocked fallback: simple keyword scorer.
      // Returns a getSentiment(tokens) interface compatible with Natural.js.
      const POS = ['good','great','happy','excellent','love','like','nice','wonderful',
                   'amazing','fantastic','thanks','thank','yes','awesome','glad','enjoy'];
      const NEG = ['bad','terrible','hate','angry','sad','awful','horrible','disappointed',
                   'frustrated','annoyed','wrong','worst','no','fail','unhappy','boring'];
      this._analyzer = {
        getSentiment(tokens) {
          let score = 0;
          tokens.forEach(t => {
            const w = t.toLowerCase();
            if (POS.includes(w)) score += 0.5;
            if (NEG.includes(w)) score -= 0.5;
          });
          return Math.max(-1, Math.min(1, score));
        }
      };
      MetaLog.log('system', 'EmotionModule: using offline keyword fallback for sentiment.');
      return this._analyzer;
    }

    /** Clamp a value to [0, 1] â€” prevents emotion vector drift. */
    _clamp(v) { return Math.max(0, Math.min(1, v)); }

    analyzeSentiment(text) {
      let score = 0;
      let label = 'Neutral';
      const tokens = text.split(/\s+/);

      // Pass 1: check custom domain lexicon for any token matches
      let customScore = 0;
      let customHits  = 0;
      tokens.forEach(t => {
        const w = t.toLowerCase().replace(/[^\w]/g, '');
        if (Object.prototype.hasOwnProperty.call(this._customLexicon, w)) {
          customScore += this._customLexicon[w];
          customHits++;
        }
      });

      if (customHits > 0) {
        // Custom lexicon had relevant tokens â€” use its score
        score = Math.max(-1, Math.min(1, customScore));
        MetaLog.log('emotion', `Custom lexicon matched ${customHits} token(s), score: ${score.toFixed(2)}`);
      } else {
        // Pass 2: fall back to Natural.js / offline keyword scorer
        const analyzer = this._getAnalyzer();
        if (analyzer) {
          try {
            score = analyzer.getSentiment(tokens);
          } catch (e) { /* ignore */ }
        }
      }

      if (score > 0) label = 'Positive';
      else if (score < 0) label = 'Negative';

      // Update emotional vector â€” all values clamped to [0, 1]
      selfModel.updateEmotions({
        happiness:   this._clamp(score > 0 ? 0.8 : score < 0 ? 0.2 : 0.5),
        frustration: this._clamp(score < 0 ? 0.5 : 0.0)
      });

      MetaLog.log('emotion', `Sentiment ${label} (score: ${score.toFixed(2)})`);
      return { label, score, description: `Sentiment: ${label} (score: ${score.toFixed(2)}).` };
    }
  }

  /* ================================================================
     SECTION 6 â€” ReasoningModule
     ================================================================ */
  class ReasoningModule {
    decide(input) {
      let tokens = [];
      try {
        const tokenizer = new natural.WordTokenizer();
        tokens = tokenizer.tokenize(input);
      } catch (e) {
        tokens = input.split(/\s+/);
      }

      const lower = tokens.map(t => t.toLowerCase());
      let reasoning = `Reasoning over tokens: ${tokens.join(', ')}.`;

      if (lower.includes('plan')) {
        reasoning = 'Planning: Analyzing your request and forming a rough plan.';
      } else if (lower.includes('help') || lower.includes('how')) {
        reasoning = 'Assistance intent detected: formulating a helpful reply.';
      }

      MetaLog.log('reasoning', reasoning);
      return reasoning;
    }
  }

  /* ================================================================
     SECTION 7 â€” SelfReflectionModule
     ================================================================ */
  class SelfReflectionModule {
    /**
     * @param {string} currentResponseSummary - snippet of the response being reflected on
     * @param {number} sentimentScore - raw sentiment score from EmotionModule (-1 to 1 range)
     */
    reflect(currentResponseSummary, sentimentScore = 0) {
      // Confidence is now derived from sentiment certainty rather than random.
      // Clear positive or negative sentiment â†’ higher confidence (the system
      // "knows" how to interpret the signal); neutral â†’ lower confidence.
      const certainty = Math.abs(sentimentScore);           // 0 = neutral, 1 = strong signal
      const confidence = Math.round(60 + certainty * 30);  // 60â€“90 range
      selfModel.updateState({ confidence });

      const label = confidence >= 80 ? 'High' : confidence >= 70 ? 'Medium' : 'Low';
      const reflection =
        `Reflection: Confidence estimated as ${label} (${confidence}/100, ` +
        `based on sentiment certainty ${certainty.toFixed(2)}). ` +
        `Core capabilities: ${selfModel.capabilities.slice(0, 3).join(', ')}.`;

      MetaLog.log('reflection', currentResponseSummary
        ? currentResponseSummary.slice(0, 80)
        : reflection);
      return reflection;
    }
  }

  /* ================================================================
     SECTION 7b â€” NeuralNLU
     A small TensorFlow.js bag-of-words intent classifier.

     Design principles:
     - Coordinator.process stays SYNCHRONOUS. The neural model pre-caches
       its prediction for the current input in _cachedIntent so NLUModule
       can read it without awaiting.
     - Rule-based NLU remains primary. Neural prediction only overrides
       when its confidence exceeds CONFIDENCE_THRESHOLD (0.70).
     - Training is gated behind a dev-only panel â€” visitors never trigger it.
     - Trained weights are stored in IndexedDB via TF.js, so the model
       survives page reloads without retraining.
     ================================================================ */
  const NeuralNLU = (() => {
    // â”€â”€ Intent registry (must match NLUModule._intentRules intents) â”€â”€
    const INTENTS = [
      'ask_self', 'ask_mood', 'ask_thoughts', 'remember', 'recall',
      'provide_name', 'provide_preference', 'ask_tom',
      'gratitude', 'user_apology', 'humor_request', 'continue_topic',
      'time_query', 'export_data', 'ask_metrics', 'chitchat'
    ];
    const INTENT_TO_IDX = Object.fromEntries(INTENTS.map((n, i) => [n, i]));
    const NUM_CLASSES    = INTENTS.length;
    const CONFIDENCE_THRESHOLD = 0.70;
    const MODEL_KEY      = 'indexeddb://alex-intent-model';

    // â”€â”€ Seed training data (curated; add more to improve accuracy) â”€â”€
    const SEED_DATA = [
      // ask_self
      { text: 'who are you',                  intent: 'ask_self' },
      { text: 'what are you',                 intent: 'ask_self' },
      { text: 'tell me about yourself',       intent: 'ask_self' },
      { text: 'what can you do',              intent: 'ask_self' },
      { text: 'describe yourself',            intent: 'ask_self' },
      // ask_mood
      { text: 'how do you feel',              intent: 'ask_mood' },
      { text: 'what is your mood',            intent: 'ask_mood' },
      { text: 'are you happy',                intent: 'ask_mood' },
      { text: 'what is your current emotion', intent: 'ask_mood' },
      // ask_thoughts
      { text: 'show thoughts',                intent: 'ask_thoughts' },
      { text: 'debug',                        intent: 'ask_thoughts' },
      { text: 'how did you decide that',      intent: 'ask_thoughts' },
      { text: 'show internal thoughts',       intent: 'ask_thoughts' },
      // remember
      { text: 'remember the meeting is at 3', intent: 'remember' },
      { text: 'remember my favourite color is blue', intent: 'remember' },
      { text: 'remember this',                intent: 'remember' },
      // recall
      { text: 'recall what I told you',       intent: 'recall' },
      { text: 'what did you remember',        intent: 'recall' },
      { text: 'do you recall',                intent: 'recall' },
      // provide_name
      { text: 'my name is Alex',              intent: 'provide_name' },
      { text: 'call me Jordan',               intent: 'provide_name' },
      { text: 'my name is Sam',               intent: 'provide_name' },
      // provide_preference
      { text: 'I like short answers',         intent: 'provide_preference' },
      { text: 'I prefer technical detail',    intent: 'provide_preference' },
      { text: 'I like concise responses',     intent: 'provide_preference' },
      // ask_tom
      { text: 'how do you see me',            intent: 'ask_tom' },
      { text: 'how do you model me',          intent: 'ask_tom' },
      { text: 'what do you know about me',    intent: 'ask_tom' },
      // gratitude
      { text: 'thanks',                       intent: 'gratitude' },
      { text: 'thank you so much',            intent: 'gratitude' },
      { text: 'I appreciate that',            intent: 'gratitude' },
      { text: 'cheers',                       intent: 'gratitude' },
      // user_apology
      { text: 'sorry about that',             intent: 'user_apology' },
      { text: 'my bad',                       intent: 'user_apology' },
      { text: 'I apologize',                  intent: 'user_apology' },
      // humor_request
      { text: 'tell me a joke',               intent: 'humor_request' },
      { text: 'say something funny',          intent: 'humor_request' },
      { text: 'make me laugh',                intent: 'humor_request' },
      // continue_topic
      { text: 'tell me more',                 intent: 'continue_topic' },
      { text: 'elaborate please',             intent: 'continue_topic' },
      { text: 'continue',                     intent: 'continue_topic' },
      // time_query
      { text: 'what time is it',              intent: 'time_query' },
      { text: 'current time',                 intent: 'time_query' },
      // export_data
      { text: 'export training data',         intent: 'export_data' },
      { text: 'download conversation log',    intent: 'export_data' },
      // ask_metrics
      { text: 'show metrics',                 intent: 'ask_metrics' },
      { text: 'how accurate are you',         intent: 'ask_metrics' },
      { text: 'show stats',                   intent: 'ask_metrics' },
      // chitchat
      { text: 'hello',                        intent: 'chitchat' },
      { text: 'hi there',                     intent: 'chitchat' },
      { text: 'good morning',                 intent: 'chitchat' },
      { text: 'what is the meaning of life',  intent: 'chitchat' },
      { text: 'just chatting',                intent: 'chitchat' },
    ];

    // â”€â”€ Internal state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    let _vocab     = new Map();   // word â†’ index (1-based; 0 = unknown)
    let _vocabSize = 1;
    let _model     = null;        // tf.LayersModel or null
    let _ready     = false;       // true once model is trained/loaded
    // Synchronous prediction cache: populated by primeForInput()
    let _cachedInput  = null;
    let _cachedIntent = null;
    let _cachedConf   = 0;

    // â”€â”€ Vocabulary helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    function _tokenize(text) {
      return text.toLowerCase().split(/\s+/).map(t => t.replace(/[^\w]/g, '')).filter(Boolean);
    }

    function _buildVocab(samples) {
      _vocab.clear();
      _vocabSize = 1;
      samples.forEach(s => _tokenize(s.text).forEach(w => {
        if (!_vocab.has(w)) _vocab.set(w, _vocabSize++);
      }));
    }

    function _encode(text) {
      const x = new Array(_vocabSize).fill(0);
      _tokenize(text).forEach(w => {
        const idx = _vocab.get(w);
        if (idx) x[idx] += 1;
      });
      return x;
    }

    function _encodeLabel(intent) {
      const y = new Array(NUM_CLASSES).fill(0);
      y[INTENT_TO_IDX[intent] ?? INTENT_TO_IDX['chitchat']] = 1;
      return y;
    }

    // â”€â”€ Model factory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    function _buildModel(inputDim) {
      const m = tf.sequential();
      m.add(tf.layers.dense({ units: 64, activation: 'relu', inputShape: [inputDim] }));
      m.add(tf.layers.dropout({ rate: 0.2 }));
      m.add(tf.layers.dense({ units: NUM_CLASSES, activation: 'softmax' }));
      m.compile({ optimizer: tf.train.adam(0.001), loss: 'categoricalCrossentropy', metrics: ['accuracy'] });
      return m;
    }

    // â”€â”€ Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function train(extraSamples = [], onProgress = null) {
      if (typeof tf === 'undefined') {
        MetaLog.log('neural', 'TF.js not available â€” skipping neural training.');
        return false;
      }
      const samples = [...SEED_DATA, ...extraSamples];
      _buildVocab(samples);

      const xs = tf.tensor2d(samples.map(s => _encode(s.text)));
      const ys = tf.tensor2d(samples.map(s => _encodeLabel(s.intent)));

      _model = _buildModel(_vocabSize);

      await _model.fit(xs, ys, {
        epochs: 40,
        batchSize: 8,
        shuffle: true,
        callbacks: {
          onEpochEnd: (epoch, logs) => {
            if (onProgress) onProgress(epoch, logs);
          }
        }
      });

      xs.dispose();
      ys.dispose();

      // Persist vocab + model to IndexedDB
      try {
        await _model.save(MODEL_KEY);
        localStorage.setItem('alex_nlu_vocab', JSON.stringify([..._vocab.entries()]));
        localStorage.setItem('alex_nlu_vocab_size', String(_vocabSize));
        MetaLog.log('neural', `Model trained (${samples.length} samples) and saved to IndexedDB.`);
      } catch (e) {
        MetaLog.log('neural', `Model trained but save failed: ${e.message}`);
      }

      _ready = true;
      return true;
    }

    // â”€â”€ Load from IndexedDB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async function load() {
      if (typeof tf === 'undefined') return false;
      try {
        _model = await tf.loadLayersModel(MODEL_KEY);
        const storedVocab = localStorage.getItem('alex_nlu_vocab');
        const storedSize  = localStorage.getItem('alex_nlu_vocab_size');
        if (!storedVocab || !storedSize) throw new Error('Vocab missing from storage');
        _vocab     = new Map(JSON.parse(storedVocab));
        _vocabSize = parseInt(storedSize, 10);
        _ready     = true;
        MetaLog.log('neural', `Model loaded from IndexedDB (vocab size: ${_vocabSize}).`);
        return true;
      } catch (e) {
        MetaLog.log('neural', `Load failed (will need training): ${e.message}`);
        return false;
      }
    }

    // â”€â”€ Async prediction â€” call via primeForInput() before process() â”€
    async function primeForInput(text) {
      if (!_ready || !_model) {
        _cachedInput  = text;
        _cachedIntent = null;
        _cachedConf   = 0;
        return;
      }
      try {
        const x     = tf.tensor2d([_encode(text)]);
        const probs = _model.predict(x);
        const data  = await probs.data();
        x.dispose();
        probs.dispose();

        let maxIdx = 0, maxVal = data[0];
        for (let i = 1; i < data.length; i++) {
          if (data[i] > maxVal) { maxVal = data[i]; maxIdx = i; }
        }
        _cachedInput  = text;
        _cachedIntent = INTENTS[maxIdx];
        _cachedConf   = maxVal;
        MetaLog.log('neural', `Predicted: ${_cachedIntent} (conf: ${maxVal.toFixed(2)})`);
      } catch (e) {
        _cachedInput  = text;
        _cachedIntent = null;
        _cachedConf   = 0;
        MetaLog.log('neural', `Prediction error: ${e.message}`);
      }
    }

    // â”€â”€ Synchronous read of cached prediction (used by NLUModule) â”€â”€â”€
    function getCachedIntent(text) {
      if (_cachedInput === text && _cachedIntent && _cachedConf >= CONFIDENCE_THRESHOLD) {
        return { intent: _cachedIntent, confidence: _cachedConf };
      }
      return null;
    }

    // â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    return {
      get ready()     { return _ready; },
      get modelKey()  { return MODEL_KEY; },
      INTENTS,
      SEED_DATA,
      train,
      load,
      primeForInput,
      getCachedIntent
    };
  })();

  /* ================================================================
     SECTION 8 â€” NLUModule  (rule-based intent + entity classifier)
     ================================================================ */
  class NLUModule {
    constructor(emotionModule) {
      this.emotionModule = emotionModule;
      this._intentRules = [
        // Identity & self-awareness
        { rex: /(who|what) are you/i,                           intent: 'ask_self' },
        { rex: /\b(show thoughts|debug|how did you decide)\b/i, intent: 'ask_thoughts' },
        { rex: /(how do you feel|your mood|your emotion|mood)/i, intent: 'ask_mood' },
        // Memory
        { rex: /\bremember[\s:]+(.+)/i,                         intent: 'remember' },
        { rex: /\brecall\b/i,                                   intent: 'recall' },
        // User identity & preferences
        { rex: /my name is\s+([a-zA-Z0-9_-]+)/i,              intent: 'provide_name' },
        { rex: /(i like|i prefer)\s+(.+)/i,                    intent: 'provide_preference' },
        // Theory of Mind
        { rex: /(how do you see me|how do you model me|know about me)/i, intent: 'ask_tom' },
        // Conversational / social
        { rex: /\b(thanks|thank you|appreciate|cheers)\b/i,    intent: 'gratitude' },
        { rex: /\b(sorry|apologize|my bad|apologies)\b/i,      intent: 'user_apology' },
        { rex: /\b(joke|funny|make me laugh|humor)\b/i,        intent: 'humor_request' },
        // Continuation / elaboration
        { rex: /\b(continue|more|elaborate|explain further|go on)\b/i, intent: 'continue_topic' },
        // Time
        { rex: /\b(what time|current time|time is it)\b/i,     intent: 'time_query' },
        // Training / metrics (meta)
        { rex: /\b(export|download|training data|conversation log)\b/i, intent: 'export_data' },
        { rex: /\b(metrics|accuracy|stats|how accurate)\b/i,   intent: 'ask_metrics' },
        // Neural NLU control (dev)
        { rex: /\b(train neural|train nlu|train model)\b/i,    intent: 'train_neural' },
        { rex: /\b(neural status|nlu status|is neural ready)\b/i, intent: 'ask_neural' },
      ];
    }

    parse(input) {
      let intent = 'chitchat';
      const entities = [];

      // â”€â”€ Rule-based pass (always runs as safety net) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      for (const rule of this._intentRules) {
        const m = input.match(rule.rex);
        if (m) {
          intent = rule.intent;
          for (let i = 1; i < m.length; i++) {
            if (m[i]) entities.push(m[i].trim());
          }
          break;
        }
      }

      // â”€â”€ Neural override (if model is ready and confident) â”€â”€â”€â”€â”€â”€â”€â”€
      // NeuralNLU.primeForInput() was called asynchronously before
      // Coordinator.process(), so getCachedIntent() is synchronous here.
      const neural = NeuralNLU.getCachedIntent(input);
      if (neural) {
        MetaLog.log('neural', `Overriding rule intent "${intent}" â†’ "${neural.intent}" (conf: ${neural.confidence.toFixed(2)})`);
        intent = neural.intent;
      }

      const sentiment = this.emotionModule.analyzeSentiment(input);
      MetaLog.log('nlu', `Intent=${intent}, sentiment=${sentiment.label}, neural=${neural ? 'yes' : 'no'}`);
      return { intent, entities, sentiment, raw: input };
    }
  }

  /* ================================================================
     SECTION 9 â€” UserModel  (Theory of Mind layer)
     ================================================================ */
  class UserModel {
    constructor() {
      this.name = null;
      this.preferences = [];
      this.moodScore   = 0;
      this.messageCount = 0;
      // Restore from session if available
      try {
        const saved = sessionStorage.getItem('userModel_alex');
        if (saved) Object.assign(this, JSON.parse(saved));
      } catch (e) { /* ignore */ }
    }

    _save() {
      try {
        sessionStorage.setItem('userModel_alex', JSON.stringify({
          name: this.name,
          preferences: this.preferences,
          moodScore: this.moodScore,
          messageCount: this.messageCount
        }));
      } catch (e) { /* ignore */ }
    }

    updateFromInput(nluResult, rawInput) {
      // Name extraction
      if (nluResult.intent === 'provide_name' && nluResult.entities[0]) {
        this.name = nluResult.entities[0];
      } else {
        const nm = rawInput.match(/my name is\s+([A-Za-z0-9_-]+)/i);
        if (nm) this.name = nm[1];
      }

      // Preferences
      if (nluResult.intent === 'provide_preference' && nluResult.entities.length) {
        this.preferences.push(nluResult.entities[nluResult.entities.length - 1]);
      }
      if (/short answer/i.test(rawInput))        this.preferences.push('short answers');
      if (/more detail|technical/i.test(rawInput)) this.preferences.push('technical detail');

      // Running mood average
      this.messageCount += 1;
      const w = 1 / this.messageCount;
      this.moodScore = (1 - w) * this.moodScore + w * (nluResult.sentiment.score || 0);

      this._save();
      MetaLog.log('usermodel', `Updated: name=${this.name}, mood=${this.moodScore.toFixed(2)}`);
    }

    summary() {
      const moodDesc = this.moodScore > 0.3 ? 'generally positive'
                     : this.moodScore < -0.3 ? 'generally negative'
                     : 'mixed/neutral';
      const namePart = this.name ? `named ${this.name}` : 'with unknown name';
      const prefPart = this.preferences.length
        ? `prefers ${[...new Set(this.preferences)].slice(-3).join(', ')}`
        : 'no known preferences';
      return `User ${namePart}, mood ${moodDesc}, ${prefPart}.`;
    }
  }

  /* ================================================================
     SECTION 10 â€” PolicyModule  (simulated learning/adaptation)
     Policy weights are persisted to localStorage so feedback-driven
     learning carries over between browser sessions.
     ================================================================ */
  class PolicyModule {
    constructor() {
      // Defaults â€” may be overwritten by _loadPolicy()
      this.verbosityLevel = 0.5;
      this.humorLevel     = 0.3;
      this.cautionLevel   = 0.4;
      this._loadPolicy(); // Restore trained weights if available
      this._sync();
    }

    _clamp(v) { return Math.max(0, Math.min(1, v)); }

    /** Restore previously trained policy weights from localStorage. */
    _loadPolicy() {
      try {
        const saved = JSON.parse(localStorage.getItem('alex_policy_weights'));
        if (saved && typeof saved.verbosityLevel === 'number') {
          this.verbosityLevel = this._clamp(saved.verbosityLevel);
          this.humorLevel     = this._clamp(saved.humorLevel);
          this.cautionLevel   = this._clamp(saved.cautionLevel);
          MetaLog.log('policy', `Loaded trained weights: v=${this.verbosityLevel.toFixed(2)}, h=${this.humorLevel.toFixed(2)}, c=${this.cautionLevel.toFixed(2)}`);
        }
      } catch (e) { /* storage unavailable â€” use defaults */ }
    }

    /** Persist current policy weights to localStorage after each update. */
    _savePolicy() {
      try {
        localStorage.setItem('alex_policy_weights', JSON.stringify({
          verbosityLevel: this.verbosityLevel,
          humorLevel:     this.humorLevel,
          cautionLevel:   this.cautionLevel
        }));
      } catch (e) { /* storage full or blocked â€” silently skip */ }
    }

    _sync() {
      selfModel.updateState({
        policy: {
          verbosityLevel: this.verbosityLevel,
          humorLevel:     this.humorLevel,
          cautionLevel:   this.cautionLevel
        },
        totalUpVotes:   selfModel.state.totalUpVotes,
        totalDownVotes: selfModel.state.totalDownVotes
      });
    }

    registerFeedback(type) {
      if (type !== 'up' && type !== 'down') return;

      // Use selfModel.updateState() consistently â€” no direct mutation of selfModel.state
      if (type === 'up') {
        selfModel.updateState({
          totalUpVotes: selfModel.state.totalUpVotes + 1,
          lastFeedback: 'up'
        });
        this.verbosityLevel = this._clamp(this.verbosityLevel + 0.04);
        this.humorLevel     = this._clamp(this.humorLevel     + 0.03);
        this.cautionLevel   = this._clamp(this.cautionLevel   - 0.02);
      } else {
        selfModel.updateState({
          totalDownVotes: selfModel.state.totalDownVotes + 1,
          lastFeedback: 'down'
        });
        this.cautionLevel   = this._clamp(this.cautionLevel   + 0.08);
        this.verbosityLevel = this._clamp(this.verbosityLevel - 0.05);
        this.humorLevel     = this._clamp(this.humorLevel     - 0.05);
      }

      this._sync();
      this._savePolicy(); // Persist trained weights after every feedback event
      MetaLog.log('feedback', `type=${type}, policy=${JSON.stringify(selfModel.state.policy)}`);
      renderStatusBar();
    }

    adjustPolicyOnTurn(intent, sentimentLabel) {
      if (intent === 'ask_mood' || intent === 'ask_self') {
        this.cautionLevel = this._clamp(this.cautionLevel - 0.05);
      }
      if (sentimentLabel === 'Negative') {
        this.cautionLevel = this._clamp(this.cautionLevel + 0.08);
        this.humorLevel   = this._clamp(this.humorLevel   - 0.05);
      }
      if (sentimentLabel === 'Positive') {
        this.verbosityLevel = this._clamp(this.verbosityLevel + 0.03);
      }
      this._sync();
    }

    applyResponseStyle(text) {
      let out = text;
      if      (this.cautionLevel > 0.65) out = 'I might be mistaken, but ' + out;
      else if (this.cautionLevel > 0.5)  out = 'It seems that ' + out;
      if (this.verbosityLevel > 0.75) {
        out += '\n\nFeel free to ask me to elaborate or show examples.';
      }
      if (this.humorLevel > 0.65) out += ' ğŸ™‚';
      return out;
    }
  }

  /* ================================================================
     SECTION 10b â€” TrainingLogger
     Captures every conversation turn for offline analysis and export.
     User can say "export training data" to download as JSON.
     ================================================================ */
  class TrainingLogger {
    constructor() {
      this.conversations = [];
    }

    /** Called by Coordinator after every processed turn. */
    logTurn(userInput, botOutput, nluResult) {
      this.conversations.push({
        timestamp:  new Date().toISOString(),
        userInput,
        botOutput,
        feedback:   selfModel.state.lastFeedback,   // snapshot at log time
        intent:     nluResult.intent,
        sentiment:  nluResult.sentiment.label,
        sentScore:  nluResult.sentiment.score,
        confidence: selfModel.state.confidence,
        policy:     { ...selfModel.state.policy }
      });
    }

    /** Trigger a browser download of the conversation corpus as JSON. */
    exportJSON() {
      try {
        const json = JSON.stringify(this.conversations, null, 2);
        const blob = new Blob([json], { type: 'application/json' });
        const url  = URL.createObjectURL(blob);
        const a    = document.createElement('a');
        a.href     = url;
        a.download = `alex-training-${Date.now()}.json`;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        MetaLog.log('training', `Exported ${this.conversations.length} turns.`);
        return `Training data exported â€” ${this.conversations.length} turn(s) downloaded as JSON.`;
      } catch (e) {
        MetaLog.log('training', `Export failed: ${e.message}`);
        return 'Export failed â€” your browser may have blocked the download.';
      }
    }
  }

  /* ================================================================
     SECTION 10c â€” TrainingMetrics
     Tracks per-intent accuracy (based on user feedback as a proxy)
     and overall feedback ratio. Say "metrics" or "how accurate" to see.
     ================================================================ */
  class TrainingMetrics {
    constructor() {
      this.intentFeedback = {}; // intent â†’ { up: n, down: n }
      this.totalResponses = 0;
    }

    /** Record a turn: intent + whether the user voted up/down/null. */
    record(intent, feedback) {
      this.totalResponses++;
      if (!this.intentFeedback[intent]) {
        this.intentFeedback[intent] = { up: 0, down: 0, total: 0 };
      }
      this.intentFeedback[intent].total++;
      if (feedback === 'up')   this.intentFeedback[intent].up++;
      if (feedback === 'down') this.intentFeedback[intent].down++;
    }

    /** Return a human-readable metrics summary string. */
    report() {
      const up   = selfModel.state.totalUpVotes;
      const down = selfModel.state.totalDownVotes;
      const total = up + down;
      const ratio = total > 0 ? ((up / total) * 100).toFixed(1) : 'n/a';

      let lines = [
        `Overall approval: ${ratio}% (ğŸ‘ ${up} / ğŸ‘ ${down} of ${total} rated responses)`,
        `Total turns: ${this.totalResponses}`,
        '',
        'Per-intent breakdown:'
      ];

      for (const [intent, counts] of Object.entries(this.intentFeedback)) {
        const pct = counts.total > 0
          ? ((counts.up / counts.total) * 100).toFixed(0) + '%'
          : 'unrated';
        lines.push(`  ${intent}: ${pct} positive (${counts.up}â†‘ ${counts.down}â†“ / ${counts.total} total)`);
      }

      if (Object.keys(this.intentFeedback).length === 0) {
        lines.push('  No rated turns yet â€” use ğŸ‘/ğŸ‘ buttons to build metrics.');
      }

      return lines.join('\n');
    }
  }

  /* ================================================================
     SECTION 11 â€” Coordinator  (multi-agent orchestrator)
     ================================================================ */
  class Coordinator {
    constructor() {
      this.memory     = new MemoryModule();
      this.perception = new PerceptionModule();
      this.emotion    = new EmotionModule();
      this.reasoning  = new ReasoningModule();
      this.reflection = new SelfReflectionModule();
      this.nlu        = new NLUModule(this.emotion);
      this.userModel  = new UserModel();
      this.policy     = new PolicyModule();
      this.trainingLogger  = new TrainingLogger();   // Option D: conversation corpus
      this.trainingMetrics = new TrainingMetrics();  // Option D: accuracy tracking
    }

    process(input) {
      MetaLog.log('input', `User: "${input.slice(0, 80)}"`);

      // 1. NLU parse
      const nlu = this.nlu.parse(input);

      // 2. Update Theory-of-Mind user model
      this.userModel.updateFromInput(nlu, input);

      // 3. Policy adaptation for this turn
      this.policy.adjustPolicyOnTurn(nlu.intent, nlu.sentiment.label);

      // 4. Perception + Reasoning
      const perceptionText = this.perception.perceive(input);
      const reasoningText  = this.reasoning.decide(input);

      // 5. Memory operations
      let memPart = '';
      if (nlu.intent === 'remember') {
        const toRemember = nlu.entities[0] || input;
        this.memory.store('long', 'lastInput', toRemember);
        memPart = 'I will remember that in my long-term memory. ';
      } else if (nlu.intent === 'recall') {
        const recalled = this.memory.recall('long', 'lastInput');
        memPart = recalled
          ? `I recall you said: "${recalled}". `
          : 'I cannot recall anything stored yet. ';
      }

      // 6. Build base response, modulated by verbosity policy
      let base = '';
      if (this.policy.verbosityLevel >= 0.65) {
        base += perceptionText + '\n' + nlu.sentiment.description + '\n' + reasoningText + '\n';
      } else {
        base += reasoningText + ' ';
      }
      base += memPart;

      // 7. Intent-specific content
      if (nlu.intent === 'ask_self') {
        base += `\nI am ${selfModel.identity.name}, version ${selfModel.identity.version}. ` +
          `${selfModel.identity.description}. ` +
          `My capabilities include: ${selfModel.capabilities.join('; ')}. ` +
          `Known limitations: ${selfModel.limitations.join('; ')}.`;
      }

      if (nlu.intent === 'ask_mood') {
        const e = selfModel.emotionalVector;
        base += `\nMy current internal mood vector â€” ` +
          `happiness: ${e.happiness.toFixed(2)}, ` +
          `curiosity: ${e.curiosity.toFixed(2)}, ` +
          `frustration: ${e.frustration.toFixed(2)}.`;
      }

      if (nlu.intent === 'ask_thoughts') {
        base += '\n\nâ€” Internal Process Trace (last 5 steps) â€”\n' + MetaLog.recent(5);
      }

      if (nlu.intent === 'ask_tom') {
        base += `\nHere is how I currently model you: ${this.userModel.summary()}`;
      }

      // New intent handlers (Option A expansions)
      if (nlu.intent === 'gratitude') {
        base += `\nYou're welcome! I'm glad I could help. Feel free to ask anything else.`;
        selfModel.updateEmotions({ happiness: selfModel.emotionalVector.happiness + 0.1 });
      }

      if (nlu.intent === 'user_apology') {
        base += `\nNo need to apologize â€” I'm just here to help. What would you like to explore?`;
      }

      if (nlu.intent === 'humor_request') {
        const jokes = [
          "Why do programmers prefer dark mode? Because light attracts bugs. ğŸ›",
          "A SQL query walks into a bar, walks up to two tables and asks... 'Can I join you?'",
          "I told my neural network a joke. It didn't get it â€” said the training data was insufficient. ğŸ¤–",
          "Why did the AI go to therapy? It had too many deep issues."
        ];
        base += `\n${jokes[Math.floor(Math.random() * jokes.length)]}`;
        selfModel.updateEmotions({ happiness: this._clampEmo(selfModel.emotionalVector.happiness + 0.15) });
      }

      if (nlu.intent === 'continue_topic') {
        const lastInput = this.memory.recall('short', 'recentInput');
        base += lastInput
          ? `\nContinuing from your last message: "${lastInput.slice(0, 60)}â€¦" â€” let me elaborate further.`
          : `\nI don't have a previous topic in short-term memory to continue. Could you remind me what you'd like me to expand on?`;
      }

      if (nlu.intent === 'time_query') {
        base += `\nThe current local time is ${new Date().toLocaleTimeString()}.`;
      }

      if (nlu.intent === 'export_data') {
        base += `\n${this.trainingLogger.exportJSON()}`;
      }

      if (nlu.intent === 'ask_metrics') {
        base += `\n\nâ€” Training Metrics â€”\n${this.trainingMetrics.report()}`;
      }

      // Neural NLU status and training (dev intents)
      if (nlu.intent === 'ask_neural') {
        const status = NeuralNLU.ready
          ? `Neural NLU is active. Model loaded and ready. Confidence threshold: 70%.`
          : `Neural NLU is not yet trained. Use the "Train Neural NLU" button in the dev panel, or say "train neural".`;
        base += `\n${status}`;
      }

      if (nlu.intent === 'train_neural') {
        base += `\nStarting neural NLU training on ${NeuralNLU.SEED_DATA.length} seed samples. ` +
          `Watch the ğŸ§  dev panel for progress. This may take 10â€“30 secondsâ€¦`;
        // Fire async training without blocking the response
        const extraSamples = this.trainingLogger.conversations
          .filter(t => t.feedback === 'up' && t.intent !== 'chitchat')
          .map(t => ({ text: t.userInput, intent: t.intent }));
        NeuralNLU.train(extraSamples, (epoch, logs) => {
          MetaLog.log('neural', `Epoch ${epoch + 1}/40 â€” loss: ${logs.loss.toFixed(3)}, acc: ${(logs.acc ?? logs.val_acc ?? 0).toFixed(3)}`);
        }).then(ok => {
          MetaLog.log('neural', ok ? 'Training complete âœ“' : 'Training failed âœ—');
        });
      }

      // 8. Introspective reflection trigger â€” pass sentiment score so
      //    SelfReflectionModule can derive confidence from signal certainty.
      const lower = input.toLowerCase();
      if (lower.includes('self-aware') || lower.includes('reflect') || lower.includes('introspect')) {
        base += '\n' + this.reflection.reflect(base.slice(0, 100), nlu.sentiment.score);
      }

      // 9. Name personalisation
      if (this.userModel.name) {
        base = `Hi ${this.userModel.name}! ` + base;
      }

      // 10. Apply policy style (hedging, humor, verbosity footer)
      base = this.policy.applyResponseStyle(base.trim());

      // 11. Compact mood suffix
      base += `\n[mood: happiness ${selfModel.emotionalVector.happiness.toFixed(2)}]`;

      MetaLog.log('output', 'Response generated.');

      // Log this turn for training corpus and metrics (Option D)
      this.trainingLogger.logTurn(input, base, nlu);
      this.trainingMetrics.record(nlu.intent, selfModel.state.lastFeedback);

      return base || 'Processing complete. Tell me more.';
    }

    /** Convenience clamp used inside process() for inline emotion nudges. */
    _clampEmo(v) { return Math.max(0, Math.min(1, v)); }
  }

  /* ================================================================
     SECTION 12 â€” UI helpers
     ================================================================ */

  /** Derive mood label + color from happiness score */
  function moodFromHappiness(h) {
    if (h >= 0.65) return { label: 'happy',      color: '#4CAF50' };
    if (h <= 0.35) return { label: 'frustrated',  color: '#F44336' };
    return               { label: 'neutral',      color: '#FFC107' };
  }

  /** Update the status bar to reflect current selfModel */
  function renderStatusBar() {
    const { happiness } = selfModel.emotionalVector;
    const { label, color } = moodFromHappiness(happiness);
    const pill = document.getElementById('status-mood-pill');
    const lbl  = document.getElementById('status-mood-label');
    const votes = document.getElementById('status-votes');

    if (pill) pill.style.backgroundColor = color;
    if (lbl)  lbl.textContent = `Mood: ${label}`;
    if (votes) {
      votes.innerHTML =
        `ğŸ‘ ${selfModel.state.totalUpVotes} &nbsp; ğŸ‘ ${selfModel.state.totalDownVotes}`;
    }
  }

  /** Append a message bubble to #chat-window */
  function addMessage(text, isUser, coordinator) {
    const chatWindow = document.getElementById('chat-window');
    const msgDiv = document.createElement('div');
    msgDiv.classList.add('message', isUser ? 'user-message' : 'bot-message');

    // Set mood background colour on bot messages
    if (!isUser) {
      const { color } = moodFromHappiness(selfModel.emotionalVector.happiness);
      msgDiv.style.setProperty('--msg-mood', color);
      // Subtle left border tint
      msgDiv.style.borderLeft = `4px solid ${color}`;
    }

    // Text content
    const textNode = document.createElement('span');
    textNode.classList.add('msg-text');
    textNode.textContent = text;
    msgDiv.appendChild(textNode);

    // Feedback buttons on bot messages
    if (!isUser && coordinator) {
      const feedbackRow = document.createElement('div');
      feedbackRow.classList.add('feedback-row');
      feedbackRow.setAttribute('aria-label', 'Rate this response');

      const upBtn = document.createElement('button');
      upBtn.textContent = 'ğŸ‘';
      upBtn.setAttribute('aria-label', 'Thumbs up');
      upBtn.classList.add('feedback-up');

      const dnBtn = document.createElement('button');
      dnBtn.textContent = 'ğŸ‘';
      dnBtn.setAttribute('aria-label', 'Thumbs down');
      dnBtn.classList.add('feedback-down');

      upBtn.addEventListener('click', () => {
        coordinator.policy.registerFeedback('up');
        // Update mood left-border to reflect new state
        const { color } = moodFromHappiness(selfModel.emotionalVector.happiness);
        msgDiv.style.borderLeft = `4px solid ${color}`;
        renderStatusBar();
      });

      dnBtn.addEventListener('click', () => {
        coordinator.policy.registerFeedback('down');
        const { color } = moodFromHappiness(selfModel.emotionalVector.happiness);
        msgDiv.style.borderLeft = `4px solid ${color}`;
        renderStatusBar();
      });

      feedbackRow.appendChild(upBtn);
      feedbackRow.appendChild(dnBtn);
      msgDiv.appendChild(feedbackRow);
    }

    chatWindow.appendChild(msgDiv);
    chatWindow.scrollTop = chatWindow.scrollHeight;
  }

  /* ================================================================
     SECTION 13 â€” Meta Panel wiring
     Panel visibility is owned by MetaLog._panelVisible (set in Section 2)
     so early log() calls during construction are correctly routed.
     ================================================================ */
  (function wireMetaPanel() {
    const header    = document.getElementById('meta-panel-header');
    const toggleBtn = document.getElementById('meta-toggle-btn');
    const content   = document.getElementById('meta-panel-content');

    function toggle() {
      MetaLog._panelVisible = !MetaLog._panelVisible;
      content.style.display = MetaLog._panelVisible ? 'block' : 'none';
      toggleBtn.textContent  = MetaLog._panelVisible ? 'Hide' : 'Show';
      header.setAttribute('aria-expanded', String(MetaLog._panelVisible));
      if (MetaLog._panelVisible) MetaLog._refreshPanel();
    }

    toggleBtn.addEventListener('click', e => { e.stopPropagation(); toggle(); });
    header.addEventListener('click',    e => { if (e.target !== toggleBtn) toggle(); });
    header.addEventListener('keydown',  e => { if (e.key === 'Enter' || e.key === ' ') toggle(); });
  })();

  /* ================================================================
     SECTION 14 â€” Boot
     Waits for Natural.js with a polling check (max 5 s) before
     constructing the Coordinator, so EmotionModule lazy-init has
     the best chance of finding `natural` on first use.
     ================================================================ */
  (function boot() {
    const inputEl = document.getElementById('chat-input');
    const sendBtn = document.getElementById('send-button');

    /**
     * Poll for Natural.js availability.
     * Resolves true if found within timeout, false if CDN is unavailable.
     */
    function waitForNatural(timeoutMs = 5000, intervalMs = 100) {
      return new Promise(resolve => {
        if (typeof natural !== 'undefined') return resolve(true);
        const deadline = Date.now() + timeoutMs;
        const id = setInterval(() => {
          if (typeof natural !== 'undefined') {
            clearInterval(id);
            resolve(true);
          } else if (Date.now() >= deadline) {
            clearInterval(id);
            resolve(false); // timed out â€” sentiment will be disabled
          }
        }, intervalMs);
      });
    }

    waitForNatural().then(async naturalReady => {
      if (!naturalReady) {
        console.warn('Natural.js did not load within timeout â€” sentiment analysis disabled.');
        MetaLog.log('system', 'Warning: Natural.js unavailable. Sentiment disabled.');
      }

      const coordinator = new Coordinator();
      window._coordinator = coordinator; // expose for debugging

      // â”€â”€ Attempt to load a previously trained neural model â”€â”€â”€â”€â”€â”€â”€â”€
      const neuralStatusEl  = document.getElementById('neural-status');
      const trainProgressEl = document.getElementById('train-progress');

      function updateNeuralStatus() {
        if (!neuralStatusEl) return;
        neuralStatusEl.textContent = NeuralNLU.ready
          ? 'âœ… Neural NLU active (IndexedDB model loaded)'
          : 'âš ï¸ Neural NLU not trained â€” using rule-based only';
        neuralStatusEl.style.color = NeuralNLU.ready ? '#a6e3a1' : '#fab387';
      }

      NeuralNLU.load().then(loaded => {
        updateNeuralStatus();
        MetaLog.log('system', loaded ? 'Neural NLU loaded from IndexedDB.' : 'No saved neural model found.');
      });

      // â”€â”€ Dev panel toggle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      const devHeader    = document.getElementById('dev-panel-header');
      const devToggleBtn = document.getElementById('dev-toggle-btn');
      const devBody      = document.getElementById('dev-panel-body');
      let devVisible     = true;

      function toggleDev() {
        devVisible = !devVisible;
        devBody.style.display    = devVisible ? 'block' : 'none';
        devToggleBtn.textContent = devVisible ? 'Hide' : 'Show';
      }
      devToggleBtn.addEventListener('click', e => { e.stopPropagation(); toggleDev(); });
      devHeader.addEventListener('click',    e => { if (e.target !== devToggleBtn) toggleDev(); });
      devHeader.addEventListener('keydown',  e => { if (e.key === 'Enter' || e.key === ' ') toggleDev(); });

      // â”€â”€ Train with seed data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      document.getElementById('btn-train-neural').addEventListener('click', async () => {
        trainProgressEl.textContent = 'Trainingâ€¦ epoch 0/40';
        await NeuralNLU.train([], (epoch, logs) => {
          trainProgressEl.textContent =
            `Epoch ${epoch + 1}/40 â€” loss: ${logs.loss.toFixed(3)}`;
        });
        trainProgressEl.textContent = NeuralNLU.ready
          ? 'âœ… Training complete! Neural NLU now active.'
          : 'âŒ Training failed â€” check console.';
        updateNeuralStatus();
      });

      // â”€â”€ Train with upvoted conversation data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      document.getElementById('btn-train-with-feedback').addEventListener('click', async () => {
        const extra = coordinator.trainingLogger.conversations
          .filter(t => t.feedback === 'up' && t.intent !== 'chitchat')
          .map(t => ({ text: t.userInput, intent: t.intent }));
        const total = NeuralNLU.SEED_DATA.length + extra.length;
        trainProgressEl.textContent = `Training on ${total} samples (${extra.length} from feedback)â€¦ epoch 0/40`;
        await NeuralNLU.train(extra, (epoch, logs) => {
          trainProgressEl.textContent =
            `Epoch ${epoch + 1}/40 â€” loss: ${logs.loss.toFixed(3)}`;
        });
        trainProgressEl.textContent = NeuralNLU.ready
          ? `âœ… Done! ${total} samples, neural NLU active.`
          : 'âŒ Training failed â€” check console.';
        updateNeuralStatus();
      });

      MetaLog.log('system', `Alex-Web-Agent online. Natural.js ready=${naturalReady}.`);
      renderStatusBar();

      // Welcome message
      addMessage(
        'Alex online. I\'m a modular metacognitive chatbot running entirely in your browser.\n' +
        (naturalReady ? '' : 'âš ï¸ Sentiment analysis offline (CDN unavailable).\n') +
        'Try: "Who are you?" Â· "How do you feel?" Â· "Show thoughts" Â· "Tell me a joke"\n' +
        '"Remember: [something]" Â· "Recall" Â· "Metrics" Â· "Export training data"\n' +
        '"Neural status" Â· "Train neural" â€” or use the âš—ï¸ dev panel (bottom-left) to train the neural NLU.',
        false, coordinator
      );
      MetaLog._refreshPanel();

      /** Send handler â€” async so we can prime the neural model before processing */
      async function sendMessage() {
        const text = inputEl.value.trim();
        if (!text) return;

        addMessage(text, true, null);
        coordinator.memory.store('short', 'recentInput', text);
        inputEl.value = '';
        inputEl.style.height = 'auto';

        // Prime neural intent prediction asynchronously BEFORE process()
        // so NLUModule.parse() can read the cached result synchronously.
        await NeuralNLU.primeForInput(text);

        // Small delay to simulate pipeline processing
        setTimeout(() => {
          let response;
          try {
            response = coordinator.process(text);
          } catch (err) {
            response = `An internal error occurred: ${err.message}`;
            MetaLog.log('error', err.message);
          }
          addMessage(response, false, coordinator);
          renderStatusBar();
          MetaLog._refreshPanel();
        }, 350);
      }

      sendBtn.addEventListener('click', sendMessage);

      inputEl.addEventListener('keydown', e => {
        // Enter sends; Shift+Enter inserts newline
        if (e.key === 'Enter' && !e.shiftKey) {
          e.preventDefault();
          sendMessage();
        }
      });

      // Auto-grow textarea
      inputEl.addEventListener('input', () => {
        inputEl.style.height = 'auto';
        inputEl.style.height = Math.min(inputEl.scrollHeight, 150) + 'px';
      });
    });
  })();
  </script>
</body>
</html>
